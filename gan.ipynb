{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(label_dim, label_dim)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        labels = self.label_emb(labels)\n",
    "        gen_input = torch.cat((noise, labels), dim=1)\n",
    "        return self.net(gen_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(label_dim, label_dim)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim + label_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        labels = self.label_emb(labels)\n",
    "        disc_input = torch.cat((inputs, labels), dim=1)\n",
    "        return self.net(disc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(data, labels, epochs=300, batch_size=32, noise_dim=100, lr=3e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    data = data.float() #for precision\n",
    "    labels = labels.long() #for embeddings (int64)\n",
    "    \n",
    "    dataset = TensorDataset(data, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    G = Generator(noise_dim, 8, data.shape[1] * data.shape[2]).to(device) #takes noise_dim = 100, labels 8 as i/p and produces 30 * 50 shape o/p\n",
    "    D = Discriminator(data.shape[1] * data.shape[2], 8).to(device) # 30 * 50 shape i/p and 8 labels, produces single probability as o/p\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_g = optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_d = optim.Adam(D.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #print(f'Starting epoch {epoch + 1}')\n",
    "        for real_data, real_labels in dataloader:\n",
    "            real_data = real_data.to(device).view(-1, data.shape[1] * data.shape[2])\n",
    "            real_labels = real_labels.to(device)\n",
    "            \n",
    "            batch_size = real_data.size(0)\n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_labels = torch.randint(0, 8, (batch_size,)).to(device)\n",
    "            fake_data = G(noise, fake_labels)\n",
    "            \n",
    "            real_targets = torch.ones(batch_size, 1).to(device)\n",
    "            fake_targets = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            outputs = D(real_data, real_labels) #discriminator o/p on real data\n",
    "            loss_real = criterion(outputs, real_targets) #compare it with 1\n",
    "            loss_real.backward()\n",
    "            \n",
    "            outputs = D(fake_data.detach(), fake_labels) #discriminator o/p on fake data\n",
    "            loss_fake = criterion(outputs, fake_targets) #compare it with 0\n",
    "            loss_fake.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_g.zero_grad()\n",
    "            outputs = D(fake_data, fake_labels)\n",
    "            loss_g = criterion(outputs, real_targets)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "        \n",
    "        #print(f'Epoch [{epoch + 1}/{epochs}] completed')\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], D Loss: {loss_real + loss_fake:.4f}, G Loss: {loss_g:.4f}')\n",
    "            torch.save(G.state_dict(), f'generator_{epoch + 1}.pth')\n",
    "            \n",
    "    return G, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data_mm_user1.pth')  \n",
    "labels = torch.load('labels_user1.pth')  \n",
    "\n",
    "print(f'Data size: {data.shape}')\n",
    "print(f'Labels size: {labels.shape}')\n",
    "\n",
    "G, D = train_gan(data, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
